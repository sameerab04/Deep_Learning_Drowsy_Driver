{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "CLASSES = 2\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Image_path     label_x     label_y  \\\n",
      "0  frame_0149_jpg.rf.ad848af69b7adc7a4d67f8d82b92...      0.6625  0.15390625   \n",
      "1  frame_0161_jpg.rf.a7d9f87c6556f2d980a350eb857d...  0.72265625    0.190625   \n",
      "2  frame_0077_jpg.rf.33fd47b720cd708a804198f25d15...  0.40078125  0.34765625   \n",
      "3  frame_0063_jpg.rf.4624fa9ce940d4a3064911fcb3ce...  0.42578125      0.3375   \n",
      "4  frame_0175_jpg.rf.c07c9544bfd1df4e226182f80058...  0.77109375  0.24296875   \n",
      "\n",
      "      label_w     label_h class  \n",
      "0    0.246875   0.2265625     1  \n",
      "1       0.225  0.24609375     1  \n",
      "2  0.47578125   0.0984375     0  \n",
      "3   0.4109375   0.1609375     0  \n",
      "4     0.29375   0.3109375     1  \n",
      "                                            Image_path     label_x  \\\n",
      "767  frame_0077_jpg.rf.3a66aface3c9af519f2ca0fd1a0e...    0.478125   \n",
      "70   frame_0061_jpg.rf.cfa87e213bfb60d9a8c9327dca5b...   0.4078125   \n",
      "855  frame_0028_jpg.rf.19e32f8b894307391def3413c3d1...  0.81484375   \n",
      "485  frame_0191_jpg.rf.e7f6ac183ee8ac8ce7bb666ca19c...  0.53515625   \n",
      "644  frame_0049_jpg.rf.f0c492fa6eb8522e02484a207d7f...    0.503125   \n",
      "\n",
      "        label_y     label_w     label_h class  \n",
      "767  0.52578125    0.415625    0.096875     0  \n",
      "70    0.3453125    0.453125     0.11875     0  \n",
      "855    0.365625   0.1421875   0.0640625     1  \n",
      "485  0.35703125  0.15078125  0.14921875     1  \n",
      "644       0.525   0.4453125   0.1046875     1  \n",
      "                                          Image_path     label_x     label_y  \\\n",
      "0  frame_0001_jpg.rf.8b7a3fd43952e6fb49d005af8ab5...     0.61875  0.25546875   \n",
      "1  frame_0101_jpg.rf.e9950d83f267efea842042bb5d08...  0.40703125   0.3328125   \n",
      "2  frame_0110_jpg.rf.19798f26be9e970155fcfd9e0056...      0.3875  0.32109375   \n",
      "3  frame_0201_jpg.rf.2e37c2b0f354d27a1acff8cfa800...  0.76484375  0.24609375   \n",
      "4  frame_0203_jpg.rf.1152e2258504052bd774a4f22731...  0.78203125   0.2234375   \n",
      "\n",
      "      label_w     label_h class  \n",
      "0  0.21484375   0.1234375     0  \n",
      "1  0.46015625    0.134375     0  \n",
      "2  0.45546875   0.1234375     0  \n",
      "3  0.16015625  0.31015625     1  \n",
      "4   0.2453125  0.30859375     1  \n"
     ]
    }
   ],
   "source": [
    "def read_label_file(label_file):\n",
    "    data = []\n",
    "    with open(label_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            # Split each line by space (assuming space-separated values)\n",
    "            parts = line.strip().split()\n",
    "            # Extract relevant information from the line\n",
    "            image_path = parts[0]  # Assuming the image path is the first item\n",
    "            # Assuming the rest of the items in the line are label values\n",
    "            labels = parts[1:]\n",
    "            # Append the extracted information as a tuple to the data list\n",
    "            data.append((image_path, *labels))\n",
    "    # Convert the data list to a pandas DataFrame\n",
    "    df = pd.DataFrame(data)  \n",
    "    return df\n",
    "\n",
    "# Read Train Labels\n",
    "label_file = '../../Drowsey_Driver_DL_Data/combined_classification_dataset/combined_train_labels.txt'\n",
    "train_df = read_label_file(label_file)\n",
    "train_df.drop(train_df.columns[1], axis=1, inplace=True)\n",
    "train_df.columns = [\"Image_path\", 'label_x', 'label_y', 'label_w', 'label_h', 'class']\n",
    "print(train_df.head())  # Display the first few rows of the DataFrame\n",
    "\n",
    "# Split the combined train dataframe into train and validation sets\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "print(val_df.head())\n",
    "\n",
    "# Read Test Labels\n",
    "label_file = '../../Drowsey_Driver_DL_Data/combined_classification_dataset/combined_test_labels.txt'\n",
    "test_df = read_label_file(label_file)\n",
    "test_df.drop(test_df.columns[1], axis=1, inplace=True)\n",
    "test_df.columns = [\"Image_path\", 'label_x', 'label_y', 'label_w', 'label_h', 'class']\n",
    "print(test_df.head())  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_path</th>\n",
       "      <th>label_x</th>\n",
       "      <th>label_y</th>\n",
       "      <th>label_w</th>\n",
       "      <th>label_h</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>frame_0121_jpg.rf.f37f9a1d112f9f10da4c183f238f...</td>\n",
       "      <td>0.46796875</td>\n",
       "      <td>0.52265625</td>\n",
       "      <td>0.42890625</td>\n",
       "      <td>0.0734375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>frame_0014_jpg.rf.37dae33a90d67e8d9641deac08e6...</td>\n",
       "      <td>0.47890625</td>\n",
       "      <td>0.51953125</td>\n",
       "      <td>0.4046875</td>\n",
       "      <td>0.1140625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>frame_0220_jpg.rf.03c2eee10097776806a914cd5bed...</td>\n",
       "      <td>0.54453125</td>\n",
       "      <td>0.27265625</td>\n",
       "      <td>0.1328125</td>\n",
       "      <td>0.16875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>frame_0225_jpg.rf.8ce65e178d0c585838cb57a21dc4...</td>\n",
       "      <td>0.49140625</td>\n",
       "      <td>0.26484375</td>\n",
       "      <td>0.1734375</td>\n",
       "      <td>0.196875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>frame_0161_jpg.rf.2f8c007fe4c291caa38e6a95b4cb...</td>\n",
       "      <td>0.75390625</td>\n",
       "      <td>0.215625</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.26875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>frame_0029_jpg.rf.1e09b74824f6ebb718e711a0a03b...</td>\n",
       "      <td>0.6203125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.2703125</td>\n",
       "      <td>0.184375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>frame_0188_jpg.rf.5a8cbde50aa511468281ffa2edfa...</td>\n",
       "      <td>0.71328125</td>\n",
       "      <td>0.18984375</td>\n",
       "      <td>0.2265625</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>frame_0022_jpg.rf.a666ebdc0b31104a8ec23adb88da...</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>0.27890625</td>\n",
       "      <td>0.3265625</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>frame_0194_jpg.rf.d8ea56d7856bacab11616a91a414...</td>\n",
       "      <td>0.53828125</td>\n",
       "      <td>0.353125</td>\n",
       "      <td>0.14453125</td>\n",
       "      <td>0.1703125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>frame_0003_jpg.rf.be6261ba0ce6d0ea92edc324912d...</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.2578125</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.1734375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>874 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Image_path     label_x  \\\n",
       "825  frame_0121_jpg.rf.f37f9a1d112f9f10da4c183f238f...  0.46796875   \n",
       "621  frame_0014_jpg.rf.37dae33a90d67e8d9641deac08e6...  0.47890625   \n",
       "529  frame_0220_jpg.rf.03c2eee10097776806a914cd5bed...  0.54453125   \n",
       "398  frame_0225_jpg.rf.8ce65e178d0c585838cb57a21dc4...  0.49140625   \n",
       "235  frame_0161_jpg.rf.2f8c007fe4c291caa38e6a95b4cb...  0.75390625   \n",
       "..                                                 ...         ...   \n",
       "106  frame_0029_jpg.rf.1e09b74824f6ebb718e711a0a03b...   0.6203125   \n",
       "270  frame_0188_jpg.rf.5a8cbde50aa511468281ffa2edfa...  0.71328125   \n",
       "860  frame_0022_jpg.rf.a666ebdc0b31104a8ec23adb88da...    0.521875   \n",
       "435  frame_0194_jpg.rf.d8ea56d7856bacab11616a91a414...  0.53828125   \n",
       "102  frame_0003_jpg.rf.be6261ba0ce6d0ea92edc324912d...      0.6625   \n",
       "\n",
       "        label_y     label_w    label_h class  \n",
       "825  0.52265625  0.42890625  0.0734375     0  \n",
       "621  0.51953125   0.4046875  0.1140625     0  \n",
       "529  0.27265625   0.1328125    0.16875     0  \n",
       "398  0.26484375   0.1734375   0.196875     0  \n",
       "235    0.215625        0.25    0.26875     1  \n",
       "..          ...         ...        ...   ...  \n",
       "106    0.234375   0.2703125   0.184375     0  \n",
       "270  0.18984375   0.2265625   0.265625     1  \n",
       "860  0.27890625   0.3265625   0.159375     0  \n",
       "435    0.353125  0.14453125  0.1703125     1  \n",
       "102   0.2578125      0.2875  0.1734375     0  \n",
       "\n",
       "[874 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def preprocess_image_and_label_train(image_name, label_x, label_y, label_w, label_h, class_label, target_size=(244, 244)):\n",
    "    # Construct the full image path\n",
    "    image_path = os.path.join('/Users/sameeraboppana/Desktop/DL_Project/Drowsey_Driver_DL_Data/combined_classification_dataset/train/images', image_name)\n",
    "    \n",
    "    # Read and preprocess the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image from {image_path}\")\n",
    "        return None, None\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    height, width, _ = image.shape\n",
    "    x, y, w, h = int(float(label_x) * width), int(float(label_y) * height), int(float(label_w) * width), int(float(label_h) * height)\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "    cropped_image = cv2.resize(cropped_image, target_size)\n",
    "    \n",
    "    # Preprocess the class label\n",
    "    class_label = int(class_label)  # Convert to integer\n",
    "    \n",
    "    return cropped_image, class_label\n",
    "\n",
    "# Lists to store preprocessed images and their corresponding class labels\n",
    "train_preprocessed_images = []\n",
    "train_class_labels = []\n",
    "\n",
    "# Iterate through each row in train_df and preprocess the images and labels\n",
    "for index, row in train_df.iterrows():\n",
    "    image_name = row['Image_path']  # Assuming this contains just the image filename\n",
    "    label_x = row['label_x']\n",
    "    label_y = row['label_y']\n",
    "    label_w = row['label_w']\n",
    "    label_h = row['label_h']\n",
    "    class_label = row['class']\n",
    "\n",
    "    # Preprocess the image and label\n",
    "    image, class_label = preprocess_image_and_label_train(image_name, label_x, label_y, label_w, label_h, class_label)\n",
    "    \n",
    "    # Append preprocessed image and class label to lists\n",
    "    train_preprocessed_images.append(image)\n",
    "    train_class_labels.append(class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (786, 244, 244, 3)\n",
      "Train labels shape: (786,)\n",
      "Validation images shape: (88, 244, 244, 3)\n",
      "Validation labels shape: (88,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_preprocessed_images, train_class_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Optionally, convert the lists to numpy arrays for compatibility with TensorFlow/Keras\n",
    "import numpy as np\n",
    "train_images = np.array(train_images)\n",
    "val_images = np.array(val_images)\n",
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)\n",
    "\n",
    "# Print the shapes of the train and validation sets\n",
    "print(\"Train images shape:\", train_images.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Validation images shape:\", val_images.shape)\n",
    "print(\"Validation labels shape:\", val_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 15s]\n",
      "val_accuracy: 0.5795454382896423\n",
      "\n",
      "Best val_accuracy So Far: 0.9431818127632141\n",
      "Total elapsed time: 00h 18m 10s\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "# Define your CNN model architecture\n",
    "def build_model(hp):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Convolutional layers with varying number of filters\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=32),\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values=[3, 5]),\n",
    "        activation='relu',\n",
    "        input_shape=(244, 244, 3),  # Adjust input shape according to your preprocessed image size\n",
    "        kernel_regularizer=regularizers.l2(0.001)\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv_2_filter', min_value=64, max_value=128, step=32),\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values=[3, 5]),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(0.001)\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv_3_filter', min_value=128, max_value=256, step=32),\n",
    "        kernel_size=hp.Choice('conv_3_kernel', values=[3, 5]),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(0.001)\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('dense_units', min_value=64, max_value=256, step=32),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(0.001)\n",
    "    ))\n",
    "    model.add(layers.Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  # Assuming binary classification, adjust if needed\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop']),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Initialize Keras Tuner RandomSearch\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Number of hyperparameter combinations to try\n",
    "    directory='my_dir',\n",
    "    project_name='random_search'\n",
    ")\n",
    "\n",
    "# Run the hyperparameter search\n",
    "tuner.search(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preprocessed_images = []\n",
    "test_class_labels = []\n",
    "\n",
    "def preprocess_image_and_label_test(image_name, label_x, label_y, label_w, label_h, class_label, target_size=(244, 244)):\n",
    "    # Construct the full image path\n",
    "    image_path = os.path.join('/Users/sameeraboppana/Desktop/DL_Project/combined_classification_dataset/test/images', image_name)\n",
    "    \n",
    "    # Read and preprocess the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image from {image_path}\")\n",
    "        return None, None\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    height, width, _ = image.shape\n",
    "    x, y, w, h = int(float(label_x) * width), int(float(label_y) * height), int(float(label_w) * width), int(float(label_h) * height)\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "    cropped_image = cv2.resize(cropped_image, target_size)\n",
    "    \n",
    "    # Preprocess the class label\n",
    "    class_label = int(class_label)  # Convert to integer\n",
    "    \n",
    "    return cropped_image, class_label\n",
    "\n",
    "\n",
    "# Iterate through each row in test_df and preprocess the images and labels\n",
    "for index, row in test_df.iterrows():\n",
    "    image_name = row['Image_path']  # Assuming this contains just the image filename\n",
    "    label_x = row['label_x']\n",
    "    label_y = row['label_y']\n",
    "    label_w = row['label_w']\n",
    "    label_h = row['label_h']\n",
    "    class_label = row['class']\n",
    "\n",
    "    # Preprocess the image and label\n",
    "    image, class_label = preprocess_image_and_label_test(image_name, label_x, label_y, label_w, label_h, class_label)\n",
    "    \n",
    "    # Append preprocessed image and class label to lists\n",
    "    test_preprocessed_images.append(image)\n",
    "    test_class_labels.append(class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 494ms/step - accuracy: 0.7221 - loss: 2.1068 - val_accuracy: 0.6364 - val_loss: 2.2237\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 477ms/step - accuracy: 0.7366 - loss: 0.8845 - val_accuracy: 0.8409 - val_loss: 0.5912\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 467ms/step - accuracy: 0.8000 - loss: 0.9185 - val_accuracy: 0.7386 - val_loss: 0.6779\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 844ms/step - accuracy: 0.7773 - loss: 0.6957 - val_accuracy: 0.7273 - val_loss: 0.7257\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 467ms/step - accuracy: 0.7633 - loss: 0.8646 - val_accuracy: 0.7614 - val_loss: 0.7202\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 473ms/step - accuracy: 0.7694 - loss: 0.8430 - val_accuracy: 0.9091 - val_loss: 0.4550\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 779ms/step - accuracy: 0.8404 - loss: 0.5625 - val_accuracy: 0.9091 - val_loss: 0.5032\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 491ms/step - accuracy: 0.8565 - loss: 0.5327 - val_accuracy: 0.8864 - val_loss: 0.4982\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 485ms/step - accuracy: 0.8530 - loss: 0.4919 - val_accuracy: 0.9205 - val_loss: 0.4528\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 475ms/step - accuracy: 0.8675 - loss: 0.4478 - val_accuracy: 0.8523 - val_loss: 0.5037\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.8624 - loss: 0.4302\n",
      "Test Loss: 0.41673749685287476\n",
      "Test Accuracy: 0.8717948794364929\n"
     ]
    }
   ],
   "source": [
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Train the best model on the combined train and validation data\n",
    "best_model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))\n",
    "\n",
    "# Convert test_preprocessed_images and test_class_labels to numpy arrays\n",
    "test_images = np.array(test_preprocessed_images)\n",
    "test_labels = np.array(test_class_labels)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "test_loss, test_accuracy = best_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
      "Actual Label: 0 Predicted Label: [0]\n",
      "Actual Label: 0 Predicted Label: [0]\n",
      "Actual Label: 0 Predicted Label: [0]\n",
      "Actual Label: 1 Predicted Label: [1]\n",
      "Actual Label: 1 Predicted Label: [1]\n",
      "Actual Label: 0 Predicted Label: [0]\n",
      "Actual Label: 1 Predicted Label: [0]\n",
      "Actual Label: 1 Predicted Label: [0]\n",
      "Actual Label: 0 Predicted Label: [0]\n",
      "Actual Label: 0 Predicted Label: [0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = best_model.predict(test_images)\n",
    "\n",
    "# Convert predictions to class labels (assuming binary classification)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Display some predictions\n",
    "for i in range(10):  # Displaying predictions for the first 10 samples\n",
    "    print(\"Actual Label:\", test_labels[i], \"Predicted Label:\", predicted_labels[i])\n",
    "\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "def plot_confusion_matrix(cm):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(test_labels))\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted label for the new image: 0\n"
     ]
    }
   ],
   "source": [
    "new_image_path = \"/Users/sameeraboppana/Desktop/DL_Project/PHOTO-2024-05-29-19-11-53.jpg\"\n",
    "\n",
    "# Read the new image\n",
    "new_image = cv2.imread(new_image_path)\n",
    "if new_image is None:\n",
    "    print(f\"Error: Unable to load image from {new_image_path}\")\n",
    "else:\n",
    "    # Preprocess the new image (resize, normalize, etc.)\n",
    "    preprocessed_new_image = cv2.resize(new_image, (244, 244))  # Resize to match the input size of your model\n",
    "    \n",
    "    # Make prediction on the preprocessed new image\n",
    "    prediction = model.predict(np.expand_dims(preprocessed_new_image, axis=0))\n",
    "    \n",
    "    # Convert prediction to class label\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    \n",
    "    print(\"Predicted label for the new image:\", predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncropped Image Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def preprocess_image_and_label_train(image_name, label_x, label_y, label_w, label_h, class_label, target_size=(244, 244)):\n",
    "    # Construct the full image path\n",
    "    image_path = os.path.join('/Users/sameeraboppana/Desktop/DL_Project/Drowsey_Driver_DL_Data/combined_classification_dataset/train/images', image_name)\n",
    "    \n",
    "    # Read and preprocess the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image from {image_path}\")\n",
    "        return None, None\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize the image\n",
    "    image = cv2.resize(image, target_size)\n",
    "    \n",
    "    # Preprocess the class label\n",
    "    class_label = int(class_label)  # Convert to integer\n",
    "    \n",
    "    return image, class_label\n",
    "\n",
    "# Lists to store preprocessed images and their corresponding class labels\n",
    "train_preprocessed_images = []\n",
    "train_class_labels = []\n",
    "\n",
    "# Iterate through each row in train_df and preprocess the images and labels\n",
    "for index, row in train_df.iterrows():\n",
    "    image_name = row['Image_path']  # Assuming this contains just the image filename\n",
    "    label_x = row['label_x']\n",
    "    label_y = row['label_y']\n",
    "    label_w = row['label_w']\n",
    "    label_h = row['label_h']\n",
    "    class_label = row['class']\n",
    "\n",
    "    # Preprocess the image and label\n",
    "    image, class_label = preprocess_image_and_label_train(image_name, label_x, label_y, label_w, label_h, class_label)\n",
    "    \n",
    "    # Append preprocessed image and class label to lists\n",
    "    train_preprocessed_images.append(image)\n",
    "    train_class_labels.append(class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (786, 244, 244, 3)\n",
      "Train labels shape: (786,)\n",
      "Validation images shape: (88, 244, 244, 3)\n",
      "Validation labels shape: (88,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_preprocessed_images, train_class_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Optionally, convert the lists to numpy arrays for compatibility with TensorFlow/Keras\n",
    "import numpy as np\n",
    "train_images = np.array(train_images)\n",
    "val_images = np.array(val_images)\n",
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)\n",
    "\n",
    "# Print the shapes of the train and validation sets\n",
    "print(\"Train images shape:\", train_images.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Validation images shape:\", val_images.shape)\n",
    "print(\"Validation labels shape:\", val_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 57s]\n",
      "val_accuracy: 0.6931818127632141\n",
      "\n",
      "Best val_accuracy So Far: 0.9659090638160706\n",
      "Total elapsed time: 00h 14m 05s\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "# Define your CNN model architecture\n",
    "def build_model(hp):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Convolutional layers with varying number of filters\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=32),\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values=[3, 5]),\n",
    "        activation='relu',\n",
    "        input_shape=(244, 244, 3),  # Adjust input shape according to your preprocessed image size\n",
    "        kernel_regularizer=regularizers.l2(0.001)\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv_2_filter', min_value=64, max_value=128, step=32),\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values=[3, 5]),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(0.001)\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv_3_filter', min_value=128, max_value=256, step=32),\n",
    "        kernel_size=hp.Choice('conv_3_kernel', values=[3, 5]),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(0.001)\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('dense_units', min_value=64, max_value=256, step=32),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(0.001)\n",
    "    ))\n",
    "    model.add(layers.Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  # Assuming binary classification, adjust if needed\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop']),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Initialize Keras Tuner RandomSearch\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Number of hyperparameter combinations to try\n",
    "    directory='my_dir_uncropped',\n",
    "    project_name='random_search'\n",
    ")\n",
    "\n",
    "# Run the hyperparameter search\n",
    "tuner.search(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preprocessed_images = []\n",
    "test_class_labels = []\n",
    "\n",
    "def preprocess_image_and_label_test(image_name, label_x, label_y, label_w, label_h, class_label, target_size=(244, 244)):\n",
    "    # Construct the full image path\n",
    "    image_path = os.path.join('/Users/sameeraboppana/Desktop/DL_Project/Drowsey_Driver_DL_Data/combined_classification_dataset/test/images', image_name)\n",
    "    \n",
    "    # Read and preprocess the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image from {image_path}\")\n",
    "        return None, None\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize the image\n",
    "    image = cv2.resize(image, target_size)\n",
    "    \n",
    "    # Preprocess the class label\n",
    "    class_label = int(class_label)  # Convert to integer\n",
    "    \n",
    "    return image, class_label\n",
    "\n",
    "# Iterate through each row in test_df and preprocess the images and labels\n",
    "for index, row in test_df.iterrows():\n",
    "    image_name = row['Image_path']  # Assuming this contains just the image filename\n",
    "    label_x = row['label_x']\n",
    "    label_y = row['label_y']\n",
    "    label_w = row['label_w']\n",
    "    label_h = row['label_h']\n",
    "    class_label = row['class']\n",
    "\n",
    "    # Preprocess the image and label\n",
    "    image, class_label = preprocess_image_and_label_test(image_name, label_x, label_y, label_w, label_h, class_label)\n",
    "    \n",
    "    # Append preprocessed image and class label to lists\n",
    "    test_preprocessed_images.append(image)\n",
    "    test_class_labels.append(class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 304ms/step - accuracy: 0.7457 - loss: 2.1238 - val_accuracy: 0.9091 - val_loss: 0.3419\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 283ms/step - accuracy: 0.8131 - loss: 0.5895 - val_accuracy: 0.9205 - val_loss: 0.4864\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 298ms/step - accuracy: 0.8637 - loss: 0.5634 - val_accuracy: 0.5341 - val_loss: 7.2674\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 283ms/step - accuracy: 0.8099 - loss: 1.4990 - val_accuracy: 0.9205 - val_loss: 0.4514\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 290ms/step - accuracy: 0.8905 - loss: 0.5181 - val_accuracy: 0.9659 - val_loss: 0.3398\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.9297 - loss: 0.4086 - val_accuracy: 0.9432 - val_loss: 0.3226\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 282ms/step - accuracy: 0.9178 - loss: 0.3839 - val_accuracy: 0.9773 - val_loss: 0.2606\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 285ms/step - accuracy: 0.9252 - loss: 0.3736 - val_accuracy: 0.9659 - val_loss: 0.2558\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 282ms/step - accuracy: 0.8983 - loss: 0.4666 - val_accuracy: 0.9773 - val_loss: 0.2606\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.9064 - loss: 0.3806 - val_accuracy: 0.9773 - val_loss: 0.2695\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.9175 - loss: 0.3591\n",
      "Test Loss: 0.3513578474521637\n",
      "Test Accuracy: 0.9230769276618958\n"
     ]
    }
   ],
   "source": [
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Train the best model on the combined train and validation data\n",
    "best_model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))\n",
    "\n",
    "# Convert test_preprocessed_images and test_class_labels to numpy arrays\n",
    "test_images = np.array(test_preprocessed_images)\n",
    "test_labels = np.array(test_class_labels)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "test_loss, test_accuracy = best_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "best_model.save(\"class_uncropped.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
      "Actual Label: 0 Predicted Label: [0]\n",
      "Actual Label: 0 Predicted Label: [0]\n",
      "Actual Label: 0 Predicted Label: [0]\n",
      "Actual Label: 1 Predicted Label: [1]\n",
      "Actual Label: 1 Predicted Label: [1]\n",
      "Actual Label: 0 Predicted Label: [0]\n",
      "Actual Label: 1 Predicted Label: [1]\n",
      "Actual Label: 1 Predicted Label: [1]\n",
      "Actual Label: 0 Predicted Label: [0]\n",
      "Actual Label: 0 Predicted Label: [0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAHFCAYAAAAJ7nvFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0A0lEQVR4nO3deXyNd/r/8fdJyElCEoJsRMRaSu0lprYqbWoMXakuaOi0YVpDq4NppQsp3/5UUXSVdFF8p+iuNbV1WhSlWtRUG6RTGaUqJGRz//7QnK8joefknJOz3K+nx/149NzrdVLtlev6fO77thiGYQgAAPilIG8HAAAAqo5EDgCAHyORAwDgx0jkAAD4MRI5AAB+jEQOAIAfI5EDAODHSOQAAPgxEjkAAH6MRA6ftGvXLo0aNUrJyckKDQ1V7dq11alTJ82aNUu//PKLR6+9Y8cO9e7dW1FRUbJYLJozZ47br2GxWJSRkeH28/6erKwsWSwWWSwWrV+/vsJ2wzDUvHlzWSwW9enTp0rXWLBggbKyspw6Zv369ReNCcCl1fB2AMCFXnzxRaWnp6tVq1Z66KGH1KZNG5WUlGjbtm1atGiRNm3apJUrV3rs+nfffbcKCgq0dOlS1a1bV02aNHH7NTZt2qRGjRq5/byOioiI0Msvv1whWW/YsEHff/+9IiIiqnzuBQsWqH79+ho5cqTDx3Tq1EmbNm1SmzZtqnxdwKxI5PApmzZt0n333af+/ftr1apVslqttm39+/fXxIkTtXr1ao/G8M0332jMmDFKTU312DW6d+/usXM7YujQoXrjjTf03HPPKTIy0rb+5ZdfVkpKivLz86sljpKSElksFkVGRnr9ZwL4K1rr8CkzZsyQxWLRCy+8YJfEy4WEhOhPf/qT7fPZs2c1a9YsXXbZZbJarYqJidFdd92lH3/80e64Pn36qG3bttq6dat69uyp8PBwNW3aVE899ZTOnj0r6f/azqWlpVq4cKGtBS1JGRkZtn8+X/kxBw4csK1bu3at+vTpo3r16iksLEyNGzfWTTfdpMLCQts+lbXWv/nmGw0ePFh169ZVaGioOnTooOzsbLt9ylvQb775pqZOnaqEhARFRkbqmmuu0b59+xz7IUu67bbbJElvvvmmbd2JEyf01ltv6e677670mMcee0zdunVTdHS0IiMj1alTJ7388ss6/71LTZo00e7du7Vhwwbbz6+8o1Ee+2uvvaaJEyeqYcOGslqt2r9/f4XW+tGjR5WYmKgePXqopKTEdv49e/aoVq1auvPOOx3+rkCgI5HDZ5SVlWnt2rXq3LmzEhMTHTrmvvvu08MPP6z+/fvrnXfe0RNPPKHVq1erR48eOnr0qN2+eXl5uv3223XHHXfonXfeUWpqqiZPnqzXX39dkjRw4EBt2rRJknTzzTdr06ZNts+OOnDggAYOHKiQkBC98sorWr16tZ566inVqlVLxcXFFz1u37596tGjh3bv3q25c+dqxYoVatOmjUaOHKlZs2ZV2H/KlCk6ePCgXnrpJb3wwgv67rvvNGjQIJWVlTkUZ2RkpG6++Wa98sortnVvvvmmgoKCNHTo0It+tz//+c9avny5VqxYoRtvvFF/+ctf9MQTT9j2WblypZo2baqOHTvafn4XDoNMnjxZhw4d0qJFi/Tuu+8qJiamwrXq16+vpUuXauvWrXr44YclSYWFhbrlllvUuHFjLVq0yKHvCZiCAfiIvLw8Q5IxbNgwh/bfu3evIclIT0+3W79lyxZDkjFlyhTbut69exuSjC1bttjt26ZNG+Paa6+1WyfJGDt2rN26adOmGZX957J48WJDkpGTk2MYhmH84x//MCQZO3fuvGTskoxp06bZPg8bNsywWq3GoUOH7PZLTU01wsPDjV9//dUwDMNYt26dIcm4/vrr7fZbvny5IcnYtGnTJa9bHu/WrVtt5/rmm28MwzCMrl27GiNHjjQMwzAuv/xyo3fv3hc9T1lZmVFSUmI8/vjjRr169YyzZ8/atl3s2PLr9erV66Lb1q1bZ7d+5syZhiRj5cqVxogRI4ywsDBj165dl/yOgNlQkcNvrVu3TpIqTKq68sor1bp1a33yySd26+Pi4nTllVfarbviiit08OBBt8XUoUMHhYSE6J577lF2drZ++OEHh45bu3at+vXrV6ETMXLkSBUWFlboDJw/vCCd+x6SnPouvXv3VrNmzfTKK6/o66+/1tatWy/aVi+P8ZprrlFUVJSCg4NVs2ZNPfroozp27JiOHDni8HVvuukmh/d96KGHNHDgQN12223Kzs7WvHnz1K5dO4ePB8yARA6fUb9+fYWHhysnJ8eh/Y8dOyZJio+Pr7AtISHBtr1cvXr1KuxntVp1+vTpKkRbuWbNmumf//ynYmJiNHbsWDVr1kzNmjXTs88+e8njjh07dtHvUb79fBd+l/L5BM58F4vFolGjRun111/XokWL1LJlS/Xs2bPSfb/44gsNGDBA0rm7Cj777DNt3bpVU6dOdfq6lX3PS8U4cuRInTlzRnFxcYyNA5UgkcNnBAcHq1+/ftq+fXuFyWqVKU9mhw8frrDtp59+Uv369d0WW2hoqCSpqKjIbv2F4/CS1LNnT7377rs6ceKENm/erJSUFI0fP15Lly696Pnr1at30e8hya3f5XwjR47U0aNHtWjRIo0aNeqi+y1dulQ1a9bUe++9p1tvvVU9evRQly5dqnTNyiYNXszhw4c1duxYdejQQceOHdODDz5YpWsCgYxEDp8yefJkGYahMWPGVDo5rKSkRO+++64k6eqrr5Yk22S1clu3btXevXvVr18/t8VVPvN6165dduvLY6lMcHCwunXrpueee06S9OWXX1503379+mnt2rW2xF3u1VdfVXh4uMduzWrYsKEeeughDRo0SCNGjLjofhaLRTVq1FBwcLBt3enTp/Xaa69V2NddXY6ysjLddtttslgs+vDDD5WZmal58+ZpxYoVLp8bCCTcRw6fkpKSooULFyo9PV2dO3fWfffdp8svv1wlJSXasWOHXnjhBbVt21aDBg1Sq1atdM8992jevHkKCgpSamqqDhw4oEceeUSJiYn661//6ra4rr/+ekVHRystLU2PP/64atSooaysLOXm5trtt2jRIq1du1YDBw5U48aNdebMGdvM8Guuueai5582bZree+899e3bV48++qiio6P1xhtv6P3339esWbMUFRXltu9yoaeeeup39xk4cKBmz56t4cOH65577tGxY8f09NNPV3qLYLt27bR06VItW7ZMTZs2VWhoaJXGtadNm6ZPP/1UH3/8seLi4jRx4kRt2LBBaWlp6tixo5KTk50+JxCISOTwOWPGjNGVV16pZ555RjNnzlReXp5q1qypli1bavjw4Ro3bpxt34ULF6pZs2Z6+eWX9dxzzykqKkrXXXedMjMzKx0Tr6rIyEitXr1a48eP1x133KE6depo9OjRSk1N1ejRo237dejQQR9//LGmTZumvLw81a5dW23bttU777xjG2OuTKtWrfT5559rypQpGjt2rE6fPq3WrVtr8eLFTj0hzVOuvvpqvfLKK5o5c6YGDRqkhg0basyYMYqJiVFaWprdvo899pgOHz6sMWPG6OTJk0pKSrK7z94Ra9asUWZmph555BG7zkpWVpY6duyooUOH6l//+pdCQkLc8fUAv2YxjPOe5gAAAPwKY+QAAPgxEjkAAH6MRA4AgB8jkQMA4MdI5AAA+DESOQAAfsyv7yM/e/asfvrpJ0VERDj12EcAgG8wDEMnT55UQkKCgoI8V1ueOXPmkq8SdlRISIjtkc2+wq8T+U8//eTwe6sBAL4rNzdXjRo18si5z5w5o7CIelJpocvniouLU05Ojk8lc79O5BEREZKkkDYjZAnmCU8ITIfWP+3tEACPOZmfr+bJibb/n3tCcXGxVFooa5sRkiu5oqxYeXuyVVxcTCJ3l/J2uiU4hESOgBUZGentEACPq5bh0RqhLuUKw+Kb08r8OpEDAOAwiyRXfmHw0alYJHIAgDlYgs4trhzvg3wzKgAA4BAqcgCAOVgsLrbWfbO3TiIHAJgDrXUAAOBrqMgBAOZAax0AAH/mYmvdR5vYvhkVAABwCBU5AMAcaK0DAODHmLUOAAB8DRU5AMAcaK0DAODHArS1TiIHAJhDgFbkvvnrBQAAcAgVOQDAHGitAwDgxywWFxM5rXUAAOBmVOQAAHMIspxbXDneB5HIAQDmEKBj5L4ZFQAAcAgVOQDAHAL0PnISOQDAHGitAwAAX0NFDgAwB1rrAAD4sQBtrZPIAQDmEKAVuW/+egEAABxCRQ4AMAda6wAA+DFa6wAAwNdQkQMATMLF1rqP1r4kcgCAOdBaBwAAvoaKHABgDhaLi7PWfbMiJ5EDAMwhQG8/882oAACAQ6jIAQDmEKCT3UjkAABzCNDWOokcAGAOAVqR++avFwAA+LnMzEx17dpVERERiomJ0ZAhQ7Rv3z67fQzDUEZGhhISEhQWFqY+ffpo9+7dTl2HRA4AMIfy1rorixM2bNigsWPHavPmzVqzZo1KS0s1YMAAFRQU2PaZNWuWZs+erfnz52vr1q2Ki4tT//79dfLkSYevQ2sdAGAO1dxaX716td3nxYsXKyYmRtu3b1evXr1kGIbmzJmjqVOn6sYbb5QkZWdnKzY2VkuWLNGf//xnh65DRQ4AgBPy8/PtlqKiIoeOO3HihCQpOjpakpSTk6O8vDwNGDDAto/ValXv3r31+eefOxwPiRwAYAoWi8XlRZISExMVFRVlWzIzM3/32oZhaMKECbrqqqvUtm1bSVJeXp4kKTY21m7f2NhY2zZH0FoHAJjC+cm4iieQJOXm5ioyMtK22mq1/u6h48aN065du/Svf/2r0rjOZxiGU3GSyAEAcEJkZKRdIv89f/nLX/TOO+9o48aNatSokW19XFycpHOVeXx8vG39kSNHKlTpl0JrHQBgDhY3LE4wDEPjxo3TihUrtHbtWiUnJ9ttT05OVlxcnNasWWNbV1xcrA0bNqhHjx4OX4eKHABgCu5qrTtq7NixWrJkid5++21FRETYxr2joqIUFhYmi8Wi8ePHa8aMGWrRooVatGihGTNmKDw8XMOHD3f4OiRyAAA8YOHChZKkPn362K1fvHixRo4cKUmaNGmSTp8+rfT0dB0/flzdunXTxx9/rIiICIevQyIHAJhCdVfkhmE4cEqLMjIylJGRUcWgSOQAAJOo7kReXUjkAABTCNREzqx1AAD8GBU5AMAcqnALWYXjfRCJHABgCrTWAQCAz6EiBwCYwrm3mLpSkbsvFncikQMATMEiF1vrPprJaa0DAODHqMgBAKYQqJPdSOQAAHMI0NvPaK0DAODHqMgBAObgYmvdoLUOAID3uDpG7tqMd88hkQMATCFQEzlj5AAA+DEqcgCAOQTorHUSOQDAFGitAwAAn0NFDgAwhUCtyEnkAABTCNRETmsdAAA/RkUOADCFQK3ISeQAAHMI0NvPaK0DAODHqMgBAKZAax0AAD9GIgcAwI8FaiJnjBwAAD9GRQ4AMIcAnbVOIgcAmAKtdQAA4HOoyFHBX0cO0B/7tleLpFidKSrRF7t+UMb8t7X/4BHbPg+PuV43DuikhrF1VVJSpp3fHtKTC97V9t0HvRg54JqX/nej5r3+if579IQuaxqvGRNuUo+Ozb0dFtyEitxDFixYoOTkZIWGhqpz58769NNPvR2S6fXo1Fwv/e9GDbj7ad04br5qBAdrxbxxCg8Nse3z/aEjmvQ//6s/3DZDqWNm69BPv2jF/HGqV6e2FyMHqm7Fx9s1ZfZbmjjqWm14/W9K6dBMtz6wQLl5v3g7NLiJRRZbMq/S4qOD5F5N5MuWLdP48eM1depU7dixQz179lRqaqoOHTrkzbBM75b7F+jN97bo2x/y9M13/9HYx19XYny0OrROtO3zj4+2acMX+3TwP8f07Q95+vucFYqsHabLWyR4MXKg6hYsWas7BqforiE91Co5TpkTb1bD2Lp65R8UF/BtXk3ks2fPVlpamkaPHq3WrVtrzpw5SkxM1MKFC70ZFi4QWTtUknQ8v7DS7TVrBGvEDX/QiZOF+ubf/6nO0AC3KC4p1c5vc3V1t9Z26/t2a60vduV4KSq4m0vVuItteU/y2hh5cXGxtm/frr/97W926wcMGKDPP//cS1GhMtP/epM27divvd8ftlt/7VVt9dL0UQoPram8o/m6Ydx8/XKiwEtRAlV37NdTKis7qwbREXbrG9SL0JFj+V6KCm7H7WfudfToUZWVlSk2NtZufWxsrPLy8io9pqioSEVFRbbP+fn8B+Zp/zPpVl3ePEGpY56psO3Tbf9Wr9szVa9Obd01pIcWz7hb14x6WkePn/JCpIDrLiy4DMPw2SoMKOf1yW4X/kdyqf9wMjMzFRUVZVsSExMr3Q/uMfPBW5Taq50G3TdXPx35tcL2wjPFyvnxqLZ9c0D3P7lEpWVndefgHtUfKOCienVqKzg4SEeOnbRbf/SXUxWqdPivQG2tey2R169fX8HBwRWq7yNHjlSo0stNnjxZJ06csC25ubnVEaopzXroFv2xb3v96b65OvTTMYeOsVgsCqnJHY3wPyE1a6jDZYlat+Vbu/Xrv/hWV16R7KWo4G6Bmsi99n/dkJAQde7cWWvWrNENN9xgW79mzRoNHjy40mOsVqusVmt1hWhaTz98q26+touGP/iCThWeUUy9cxVJ/qkzOlNUovDQEE28+1p9uPFr/ffoCdWNqqW0m3spIaaO3v7kSy9HD1RN+vCrde+0V9WxTWN1bZes7JWf6ce8XzTqpp7eDg1uYrFUHD5x9nhf5NXyacKECbrzzjvVpUsXpaSk6IUXXtChQ4d07733ejMs00u7uZck6f3nx9utT3/sNb353haVnT2rFk1iNWxgN9WrU0u/nCjUjj0Hdf09z+jbHyqf3wD4uhsHdNYvJwo066UP9d+j+WrdLF7L5qSrcXy0t0MDLsmriXzo0KE6duyYHn/8cR0+fFht27bVBx98oKSkJG+GZXp1u4675Pai4lLdNemlaooGqD6jb+ml0bf08nYY8JBzFbkrT3ZzYzBu5PUBzfT0dKWnp3s7DABAoHOxte6rt595fdY6AACoOq9X5AAAVIdAfWkKiRwAYAqBOmud1joAAH6MihwAYApBQRYFBVW9rDZcONaTSOQAAFOgtQ4AAHwOFTkAwBSYtQ4AgB8L1NY6iRwAYAqBWpEzRg4AgB+jIgcAmEKgVuQkcgCAKQTqGDmtdQAA/BgVOQDAFCxysbXuo+8xJZEDAEyB1joAAPA5VOQAAFNg1joAAH6M1joAAPA5VOQAAFOgtQ4AgB8L1NY6iRwAYAqBWpEzRg4AgB+jIgcAmIOLrXUffbAbFTkAwBzKW+uuLM7YuHGjBg0apISEBFksFq1atcpu+8iRIyucv3v37k5/LxI5AAAeUFBQoPbt22v+/PkX3ee6667T4cOHbcsHH3zg9HVorQMATKG6Z62npqYqNTX1kvtYrVbFxcVVPShRkQMATKK6W+uOWL9+vWJiYtSyZUuNGTNGR44ccfocVOQAADghPz/f7rPVapXVanX6PKmpqbrllluUlJSknJwcPfLII7r66qu1fft2p85HIgcAmIK7WuuJiYl266dNm6aMjAynzzd06FDbP7dt21ZdunRRUlKS3n//fd14440On4dEDgAwBXc9ECY3N1eRkZG29VWpxisTHx+vpKQkfffdd04dRyIHAMAJkZGRdoncXY4dO6bc3FzFx8c7dRyJHABgCtX9iNZTp05p//79ts85OTnauXOnoqOjFR0drYyMDN10002Kj4/XgQMHNGXKFNWvX1833HCDU9chkQMATKG6bz/btm2b+vbta/s8YcIESdKIESO0cOFCff3113r11Vf166+/Kj4+Xn379tWyZcsUERHh1HVI5AAAU6juirxPnz4yDOOi2z/66KMqx3I+7iMHAMCPUZEDAEyB95EDAODHeB85AADwOVTkAABTsMjF1rrbInEvEjkAwBSCLBYFuZDJXTnWk2itAwDgx6jIAQCmwKx1AAD8WKDOWieRAwBMIchybnHleF/EGDkAAH6MihwAYA4WF9vjPlqRk8gBAKYQqJPdaK0DAODHqMgBAKZg+e2PK8f7IhI5AMAUmLUOAAB8DhU5AMAUTP1AmLlz5zp8wvvvv7/KwQAA4CmBOmvdoUT+zDPPOHQyi8VCIgcAoBo5lMhzcnI8HQcAAB7Fa0wvUFxcrH379qm0tNSd8QAA4BHlrXVXFl/kdCIvLCxUWlqawsPDdfnll+vQoUOSzo2NP/XUU24PEAAAdyif7ObK4oucTuSTJ0/WV199pfXr1ys0NNS2/pprrtGyZcvcGhwAALg0p28/W7VqlZYtW6bu3bvb/XbSpk0bff/9924NDgAAdzH1rPXz/fzzz4qJiamwvqCgwGfbDgAAMNntN127dtX7779v+1yevF988UWlpKS4LzIAAPC7nK7IMzMzdd1112nPnj0qLS3Vs88+q927d2vTpk3asGGDJ2IEAMBlFrn2SnHfrMerUJH36NFDn332mQoLC9WsWTN9/PHHio2N1aZNm9S5c2dPxAgAgMsCddZ6lZ613q5dO2VnZ7s7FgAA4KQqJfKysjKtXLlSe/fulcViUevWrTV48GDVqME7WAAAvilQX2PqdOb95ptvNHjwYOXl5alVq1aSpH//+99q0KCB3nnnHbVr187tQQIA4KpAffuZ02Pko0eP1uWXX64ff/xRX375pb788kvl5ubqiiuu0D333OOJGAEAwEU4XZF/9dVX2rZtm+rWrWtbV7duXU2fPl1du3Z1a3AAALiTjxbVLnG6Im/VqpX++9//Vlh/5MgRNW/e3C1BAQDgbqaetZ6fn2/75xkzZuj+++9XRkaGunfvLknavHmzHn/8cc2cOdMzUQIA4CJTT3arU6eO3W8ihmHo1ltvta0zDEOSNGjQIJWVlXkgTAAAUBmHEvm6des8HQcAAB4VqLPWHUrkvXv39nQcAAB4VKA+orXKT3ApLCzUoUOHVFxcbLf+iiuucDkoAADgmCq9xnTUqFH68MMPK93OGDkAwBfxGtPfjB8/XsePH9fmzZsVFham1atXKzs7Wy1atNA777zjiRgBAHCZxeL64oucrsjXrl2rt99+W127dlVQUJCSkpLUv39/RUZGKjMzUwMHDvREnAAAoBJOV+QFBQWKiYmRJEVHR+vnn3+WdO6NaF9++aV7owMAwE0C9YEwVXqy2759+yRJHTp00PPPP6///Oc/WrRokeLj490eIAAA7kBr/Tfjx4/X4cOHJUnTpk3TtddeqzfeeEMhISHKyspyd3wAAOASnE7kt99+u+2fO3bsqAMHDujbb79V48aNVb9+fbcGBwCAuwTqrPUq30deLjw8XJ06dXJHLAAAeIyr7XEfzeOOJfIJEyY4fMLZs2dXORgAADzF1I9o3bFjh0Mn89UvCQBAoAqIl6ZsWfWEIiIivR0G4BF3vc5tnQhcJadPVdu1glSFW7UuON4XuTxGDgCAPwjU1rqv/oIBAAAcQEUOADAFi0UKMuusdQAA/F2Qi4nclWM9idY6AAB+rEqJ/LXXXtMf/vAHJSQk6ODBg5KkOXPm6O2333ZrcAAAuAsvTfnNwoULNWHCBF1//fX69ddfVVZWJkmqU6eO5syZ4+74AABwi/LWuiuLL3I6kc+bN08vvviipk6dquDgYNv6Ll266Ouvv3ZrcAAA4NKcnuyWk5Ojjh07VlhvtVpVUFDglqAAAHC3QH3WutMVeXJysnbu3Flh/Ycffqg2bdq4IyYAANyu/O1nriy+yOmK/KGHHtLYsWN15swZGYahL774Qm+++aYyMzP10ksveSJGAABcxiNafzNq1CiVlpZq0qRJKiws1PDhw9WwYUM9++yzGjZsmCdiBAAAF1GlB8KMGTNGY8aM0dGjR3X27FnFxMS4Oy4AANwqUMfIXXqyW/369d0VBwAAHhUk18a5g+SbmdzpRJ6cnHzJm+J/+OEHlwICAACOczqRjx8/3u5zSUmJduzYodWrV+uhhx5yV1wAALgVrfXfPPDAA5Wuf+6557Rt2zaXAwIAwBN4acrvSE1N1VtvveWu0wEAAAe47TWm//jHPxQdHe2u0wEA4Fbn3kde9bLaV1vrTlfkHTt2VKdOnWxLx44dFR8frylTpmjKlCmeiBEAAJeVj5G7sjhj48aNGjRokBISEmSxWLRq1Sq77YZhKCMjQwkJCQoLC1OfPn20e/dup7+X0xX5kCFD7D4HBQWpQYMG6tOnjy677DKnAwAAIBAVFBSoffv2GjVqlG666aYK22fNmqXZs2crKytLLVu21JNPPqn+/ftr3759ioiIcPg6TiXy0tJSNWnSRNdee63i4uKcORQAAK+q7sluqampSk1NrXSbYRiaM2eOpk6dqhtvvFGSlJ2drdjYWC1ZskR//vOfHY/LmaBq1Kih++67T0VFRc4cBgCA11nc8EeS8vPz7Zaq5MScnBzl5eVpwIABtnVWq1W9e/fW559/7tS5nB4j79atm3bs2OHsYQAAeFV5Re7KIkmJiYmKioqyLZmZmU7HkpeXJ0mKjY21Wx8bG2vb5iinx8jT09M1ceJE/fjjj+rcubNq1aplt/2KK65w9pQAAPiN3NxcRUZG2j5brdYqn+vCJ6UahnHJp6dWxuFEfvfdd2vOnDkaOnSoJOn++++3C6T84mVlZU4FAABAdXDXGHlkZKRdIq+K8nlmeXl5io+Pt60/cuRIhSr99zicyLOzs/XUU08pJyfHqQsAAOALLBaL09Xuhce7S3JysuLi4rRmzRp17NhRklRcXKwNGzZo5syZTp3L4URuGIYkKSkpyakLAABgRqdOndL+/fttn3NycrRz505FR0ercePGGj9+vGbMmKEWLVqoRYsWmjFjhsLDwzV8+HCnruPUGLk7fxsBAKA6VfftZ9u2bVPfvn1tnydMmCBJGjFihLKysjRp0iSdPn1a6enpOn78uLp166aPP/7YqXvIJScTecuWLX83mf/yyy9OBQAAQHWo7ref9enTx9bNrvx8FmVkZCgjI6PqQcnJRP7YY48pKirKpQsCAAD3cSqRDxs2TDExMZ6KBQAAjwmyWFx6aYorx3qSw4mc8XEAgD8z/fvIL9XnBwAA3uFwRX727FlPxgEAgGe5ONlNPlqRO/2IVgAA/FGQLApyIRu7cqwnkcgBAKZQ3befVRen334GAAB8BxU5AMAUAnXWOokcAGAKgXofOa11AAD8GBU5AMAUAnWyG4kcAGAKQXKxte6jt5/RWgcAwI9RkQMATIHWOgAAfixIrrWhfbWF7atxAQAAB1CRAwBMwWKxuPRKbl99nTeJHABgCha59gIz30zjJHIAgEnwZDcAAOBzqMgBAKbhmzW1a0jkAABTCNT7yGmtAwDgx6jIAQCmwO1nAAD4MZ7sBgAAfA4VOQDAFGitAwDgxwL1yW601gEA8GNU5AAAU6C1DgCAHwvUWeskcgCAKQRqRe6rv2AAAAAHUJEDAEwhUGetk8gBAKbAS1MAAIDPoSIHAJhCkCwKcqFB7sqxnkQiBwCYAq11AADgc6jIAQCmYPntjyvH+yISOQDAFGitAwAAn0NFDgAwBYuLs9ZprQMA4EWB2lonkQMATCFQEzlj5AAA+DEqcgCAKXD7GQAAfizIcm5x5XhfRGsdAAA/RkUOADAFWusAAPgxZq0DAACfQ0UOADAFi1xrj/toQU4iBwCYA7PWAQCAz6Eix+9a+u7nWvbeJv3nv8clSc2TYnXf7f3V88rLvBwZUDWtYmrr+jaxahIdprrhIZqz/nt9+eMJ2/YbrohXt6S6qlerpkrLDB34pVD/u/Mn/XCs0ItRw1WBOmvdqxX5xo0bNWjQICUkJMhisWjVqlXeDAcXEVu/jv6adr2Wz39Ay+c/oG4dmmtcRpb2H8jzdmhAlVhrBOnQ8UK9tvXHSrfn5Z/Ra1tzNeW9vXry43/r54JiTerXQhFWah9/Vj5r3ZXFF3k1kRcUFKh9+/aaP3++N8PA7+ib0ka9rmytJo0aqEmjBnpgVKrCw0L01d5D3g4NqJJdP+Xrra8Oa1vur5Vu33TguHbnndTPp4r1nxNntGT7jwoPCVZi3bDqDRRuZXHD4ou8+utlamqqUlNTvRkCnFRWdlYfbdyl02eK1b5NkrfDATwuOMiivs3rq6C4VIeO01qH7/GrPlFRUZGKiopsn/Pz870Yjbn8O+ewhj8wX8XFpQoPC9HcaSPUPCnW22EBHtOhYaTSr0pWSI0g/Xq6RLM+2a9TRWXeDgsuCJJFQS70x4N8tCb3q1nrmZmZioqKsi2JiYneDsk0mjRqoLcW/lVL5o7T0D+maMr/LNP+g//1dliAx+zJO6W/v/+tnvhon77+KV/jeiYzRu7nArW17leJfPLkyTpx4oRtyc3N9XZIphFSs4aSGtZX25aJ+mva9WrVNF6vr/zU22EBHlNcdlZHThXp+6OFennzIZWdNdS7eT1vhwVU4Fe/XlqtVlmtVm+HAUmGIRWXlHo7DKDaWCxSzWC/qn1wIVfLah8tyf0qkcM75rzyoXp2baW4BnVUcLpIH67fqa27vtfz00d7OzSgSqw1ghQb8X9FQYPaVjWuG6aColKdLCrTn9rFacePv+rX06WqbQ1Wv5YNVDc8RF8cPO7FqOGqQL2P3KuJ/NSpU9q/f7/tc05Ojnbu3Kno6Gg1btzYi5HhfMeOn9TfZi3Vz7/kKyI8VC2bxuv56aPVo3NLb4cGVElyvXBN6f9/f39v79JIkvTp98eUteWQEiJDdVWvpoqw1tCpolLlHCvU9I//rf+cOOOtkIGL8moi37Ztm/r27Wv7PGHCBEnSiBEjlJWV5aWocKEnJt7q7RAAt/r2v6d01+tfXnT73I0/VGM0qDauPtTFNwty7ybyPn36yDAMb4YAADCJAB0i969Z6wAAwB6JHABgDtV8I3lGRoYsFovdEhcX557vch5mrQMATMEbs9Yvv/xy/fOf/7R9Dg4OrvL1L4ZEDgAwBVffYFaVY2vUqOGRKvx8tNYBAHBCfn6+3XL+O0Au9N133ykhIUHJyckaNmyYfvjB/XdEkMgBAKbgriHyxMREu/d+ZGZmVnq9bt266dVXX9VHH32kF198UXl5eerRo4eOHTvm1u9Fax0AYA5uuv8sNzdXkZGRttUXe3T4+a/pbteunVJSUtSsWTNlZ2fbnpviDiRyAACcEBkZaZfIHVWrVi21a9dO3333nVvjobUOADAFixv+uKKoqEh79+5VfHy8m77ROSRyAIAplM9ad2VxxoMPPqgNGzYoJydHW7Zs0c0336z8/HyNGDHCrd+L1joAAB7w448/6rbbbtPRo0fVoEEDde/eXZs3b1ZSUpJbr0MiBwCYQnU/a33p0qUuXM1xJHIAgDkE6FtTGCMHAMCPUZEDAEzBG89arw4kcgCAKXjjWevVgUQOADCFAB0iZ4wcAAB/RkUOADCHAC3JSeQAAFMI1MlutNYBAPBjVOQAAFNg1joAAH4sQIfIaa0DAODPqMgBAOYQoCU5iRwAYArMWgcAAD6HihwAYArMWgcAwI8F6BA5iRwAYBIBmskZIwcAwI9RkQMATCFQZ62TyAEA5uDiZDcfzeO01gEA8GdU5AAAUwjQuW4kcgCASQRoJqe1DgCAH6MiBwCYArPWAQDwY4H6iFZa6wAA+DEqcgCAKQToXDcSOQDAJAI0k5PIAQCmEKiT3RgjBwDAj1GRAwBMwSIXZ627LRL3IpEDAEwhQIfIaa0DAODPqMgBAKYQqA+EIZEDAEwiMJvrtNYBAPBjVOQAAFOgtQ4AgB8LzMY6rXUAAPwaFTkAwBRorQMA4McC9VnrJHIAgDkE6CA5Y+QAAPgxKnIAgCkEaEFOIgcAmEOgTnajtQ4AgB+jIgcAmAKz1gEA8GcBOkhOax0AAD9GRQ4AMIUALchJ5AAAc2DWOgAA8DlU5AAAk3Bt1rqvNtdJ5AAAU6C1DgAAfA6JHAAAP0ZrHQBgCoHaWieRAwBMIVAf0UprHQAAP0ZFDgAwBVrrAAD4sUB9RCutdQAA/BgVOQDAHAK0JCeRAwBMgVnrAADA51CRAwBMgVnrAAD4sQAdIqe1DgAwCYsblipYsGCBkpOTFRoaqs6dO+vTTz917XtcgEQOAICHLFu2TOPHj9fUqVO1Y8cO9ezZU6mpqTp06JDbrkEiBwCYgsUNf5w1e/ZspaWlafTo0WrdurXmzJmjxMRELVy40G3fi0QOADCF8slurizOKC4u1vbt2zVgwAC79QMGDNDnn3/utu/l15PdDMOQJJ06edLLkQCeU3L6lLdDADym5HSBpP/7/7kn5efnu+X4C89jtVpltVor7H/06FGVlZUpNjbWbn1sbKzy8vJciuV8fp3IT/6WwK/q0MLLkQAAXHHy5ElFRUV55NwhISGKi4tTi+REl89Vu3ZtJSban2fatGnKyMi46DGWC0p5wzAqrHOFXyfyhIQE5ebmKiIiwq0/FFxcfn6+EhMTlZubq8jISG+HA7gVf7+rn2EYOnnypBISEjx2jdDQUOXk5Ki4uNjlc1WWhCurxiWpfv36Cg4OrlB9HzlypEKV7gq/TuRBQUFq1KiRt8MwpcjISP5Hh4DF3+/q5alK/HyhoaEKDQ31+HXOFxISos6dO2vNmjW64YYbbOvXrFmjwYMHu+06fp3IAQDwZRMmTNCdd96pLl26KCUlRS+88IIOHTqke++9123XIJEDAOAhQ4cO1bFjx/T444/r8OHDatu2rT744AMlJSW57RokcjjFarVq2rRpFx0TAvwZf7/hCenp6UpPT/fY+S1Gdcz5BwAAHsEDYQAA8GMkcgAA/BiJHAAAP0YiBwDAj5HI4TBPv1MX8JaNGzdq0KBBSkhIkMVi0apVq7wdEuAwEjkcUh3v1AW8paCgQO3bt9f8+fO9HQrgNG4/g0O6deumTp062b1Dt3Xr1hoyZIgyMzO9GBngXhaLRStXrtSQIUO8HQrgECpy/K7qeqcuAMB5JHL8rup6py4AwHkkcjjM0+/UBQA4j0SO31Vd79QFADiPRI7fdf47dc+3Zs0a9ejRw0tRAQAk3n4GB1XHO3UBbzl16pT2799v+5yTk6OdO3cqOjpajRs39mJkwO/j9jM4bMGCBZo1a5btnbrPPPOMevXq5e2wAJetX79effv2rbB+xIgRysrKqv6AACeQyAEA8GOMkQMA4MdI5AAA+DESOQAAfoxEDgCAHyORAwDgx0jkAAD4MRI5AAB+jEQOuCgjI0MdOnSwfR45cqRX3mV94MABWSwW7dy586L7NGnSRHPmzHH4nFlZWapTp47LsVksFq1atcrl8wCoiESOgDRy5EhZLBZZLBbVrFlTTZs21YMPPqiCggKPX/vZZ591+GlgjiRfALgUnrWOgHXddddp8eLFKikp0aeffqrRo0eroKBACxcurLBvSUmJatas6ZbrRkVFueU8AOAIKnIELKvVqri4OCUmJmr48OG6/fbbbe3d8nb4K6+8oqZNm8pqtcowDJ04cUL33HOPYmJiFBkZqauvvlpfffWV3XmfeuopxcbGKiIiQmlpaTpz5ozd9gtb62fPntXMmTPVvHlzWa1WNW7cWNOnT5ckJScnS5I6duwoi8WiPn362I5bvHixWrdurdDQUF122WVasGCB3XW++OILdezYUaGhoerSpYt27Njh9M9o9uzZateunWrVqqXExESlp6fr1KlTFfZbtWqVWrZsqdDQUPXv31+5ubl2299991117txZoaGhatq0qR577DGVlpY6HQ8A55HIYRphYWEqKSmxfd6/f7+WL1+ut956y9baHjhwoPLy8vTBBx9o+/bt6tSpk/r166dffvlFkrR8+XJNmzZN06dP17Zt2xQfH18hwV5o8uTJmjlzph555BHt2bNHS5Yssb3H/YsvvpAk/fOf/9Thw4e1YsUKSdKLL76oqVOnavr06dq7d69mzJihRx55RNnZ2ZKkgoIC/fGPf1SrVq20fft2ZWRk6MEHH3T6ZxIUFKS5c+fqm2++UXZ2ttauXatJkybZ7VNYWKjp06crOztbn332mfLz8zVs2DDb9o8++kh33HGH7r//fu3Zs0fPP/+8srKybL+sAPAwAwhAI0aMMAYPHmz7vGXLFqNevXrGrbfeahiGYUybNs2oWbOmceTIEds+n3zyiREZGWmcOXPG7lzNmjUznn/+ecMwDCMlJcW499577bZ369bNaN++faXXzs/PN6xWq/Hiiy9WGmdOTo4hydixY4fd+sTERGPJkiV265544gkjJSXFMAzDeP75543o6GijoKDAtn3hwoWVnut8SUlJxjPPPHPR7cuXLzfq1atn+7x48WJDkrF582bbur179xqSjC1bthiGYRg9e/Y0ZsyYYXee1157zYiPj7d9lmSsXLnyotcFUHWMkSNgvffee6pdu7ZKS0tVUlKiwYMHa968ebbtSUlJatCgge3z9u3bderUKdWrV8/uPKdPn9b3338vSdq7d2+Fd7CnpKRo3bp1lcawd+9eFRUVqV+/fg7H/fPPPys3N1dpaWkaM2aMbX1paalt/H3v3r1q3769wsPD7eJw1rp16zRjxgzt2bNH+fn5Ki0t1ZkzZ1RQUKBatWpJkmrUqKEuXbrYjrnssstUp04d7d27V1deeaW2b9+urVu32lXgZWVlOnPmjAoLC+1iBOB+JHIErL59+2rhwoWqWbOmEhISKkxmK09U5c6ePav4+HitX7++wrmqegtWWFiY08ecPXtW0rn2erdu3ey2BQcHS5IMN7x9+ODBg7r++ut177336oknnlB0dLT+9a9/KS0tzW4IQjp3+9iFytedPXtWjz32mG688cYK+4SGhrocJ4BLI5EjYNWqVUvNmzd3eP9OnTopLy9PNWrUUJMmTSrdp3Xr1tq8ebPuuusu27rNmzdf9JwtWrRQWFiYPvnkE40ePbrC9pCQEEnnKthysbGxatiwoX744QfdfvvtlZ63TZs2eu2113T69GnbLwuXiqMy27ZtU2lpqf7f//t/Cgo6N11m+fLlFfYrLS3Vtm3bdOWVV0qS9u3bp19//VWXXXaZpHM/t3379jn1swbgPiRy4DfXXHONUlJSNGTIEM2cOVOtWrXSTz/9pA8++EBDhgxRly5d9MADD2jEiBHq0qWLrrrqKr3xxhvavXu3mjZtWuk5Q0ND9fDDD2vSpEkKCQnRH/7wB/3888/avXu30tLSFBMTo7CwMK1evVqNGjVSaGiooqKilJGRofvvv1+RkZFKTU1VUVGRtm3bpuPHj2vChAkaPny4pk6dqrS0NP3973/XgQMH9PTTTzv1fZs1a6bS0lLNmzdPgwYN0meffaZFixZV2K9mzZr6y1/+orlz56pmzZoaN26cunfvbkvsjz76qP74xz8qMTFRt9xyi4KCgrRr1y59/fXXevLJJ53/FwHAKcxaB35jsVj0wQcfqFevXrr77rvVsmVLDRs2TAcOHLDNMh86dKgeffRRPfzww+rcubMOHjyo++6775LnfeSRRzRx4kQ9+uijat26tYYOHaojR45IOjf+PHfuXD3//PNKSEjQ4MGDJUmjR4/WSy+9pKysLLVr1069e/dWVlaW7Xa12rVr691339WePXvUsWNHTZ06VTNnznTq+3bo0EGzZ8/WzJkz1bZtW73xxhvKzMyssF94eLgefvhhDR8+XCkpKQoLC9PSpUtt26+99lq99957WrNmjbp27aru3btr9uzZSkpKcioeAFVjMdwx2AYAALyCihwAAD9GIgcAwI+RyAEA8GMkcgAA/BiJHAAAP0YiBwDAj5HIAQDwYyRyAAD8GIkcAAA/RiIHAMCPkcgBAPBjJHIAAPzY/we0UUF9DQoDaQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = best_model.predict(test_images)\n",
    "\n",
    "# Convert predictions to class labels (assuming binary classification)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Display some predictions\n",
    "for i in range(10):  # Displaying predictions for the first 10 samples\n",
    "    print(\"Actual Label:\", test_labels[i], \"Predicted Label:\", predicted_labels[i])\n",
    "\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "def plot_confusion_matrix(cm):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(test_labels))\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
